# Project Chimera: Domain Architecture Strategy

This document outlines the core architectural decisions for Project Chimera, as per Task 1.2. The strategy is derived from the principles and requirements laid out in the project's Software Requirements Specification (SRS).

## 1. Agent Pattern: Hierarchical Swarm (FastRender)

The foundational agent pattern for Project Chimera is the **Hierarchical Swarm**, specifically the **FastRender** architecture as detailed in the SRS. This pattern is chosen over a monolithic or simple sequential chain model for its superior scalability, robustness, and quality control.

The swarm consists of three specialized agent roles:

*   **Planner (The Strategist):** A high-level agent responsible for decomposing abstract goals (e.g., "promote a new product") into a concrete, executable task graph (DAG). It is stateful and reactive, capable of re-planning in response to new information or task failures.
*   **Worker (The Executor):** A stateless, ephemeral agent designed to execute a single, atomic task from the task queue (e.g., "generate an image," "draft a tweet"). Workers operate in parallel, enabling high-throughput execution. They are the primary consumers of MCP Tools.
*   **Judge (The Gatekeeper):** A specialized quality assurance and governance agent. It reviews the output of every Worker, comparing it against acceptance criteria, brand guidelines, and safety policies. The Judge has the authority to approve, reject, or escalate tasks for human review.

This hierarchical model allows for a clear separation of concerns, enabling a single human orchestrator to manage a vast network of autonomous agents effectively.

### Architectural Diagram (Mermaid.js)

```mermaid
graph TD
    subgraph "Human Orchestrator"
        A[Orchestrator Dashboard]
    end

    subgraph "FastRender Swarm"
        B(Planner Agent) -- Creates Task DAG --> C{Task Queue (Redis)}
        C -- Pops Task --> D1[Worker Agent 1]
        C -- Pops Task --> D2[Worker Agent 2]
        C -- Pops Task --> D3[Worker Agent N]

        D1 -- Submits Result --> E{Review Queue (Redis)}
        D2 -- Submits Result --> E
        D3 -- Submits Result --> E
    end
    
    subgraph "Governance Layer"
        F(Judge Agent) -- Pops for Review --> E
        F -- Approves --> G[Commit to Global State]
        F -- Rejects --> B
        F -- Escalates for HITL --> A
    end

    subgraph "External World (via MCP)"
        H((Social Media APIs))
        I((Vector DB - Weaviate))
        J((Blockchain - Coinbase AgentKit))
    end
    
    D1 -- Uses Tool --> H
    D2 -- Uses Tool --> I
    D3 -- Uses Tool --> J

```

## 2. Human-in-the-Loop (HITL) Strategy

The HITL process is not a manual bottleneck but a dynamic, risk-based safety layer integrated directly into the agent swarm's workflow. The **Judge** agent is the critical component that initiates the HITL process.

1.  **Confidence Scoring:** Every piece of content or action generated by a Worker is assigned a `confidence_score` by the model that produced it.
2.  **Automated Escalation:** The Judge agent uses this score to route the task:
    *   **High Confidence (> 0.90):** The action is automatically approved and executed.
    *   **Medium Confidence (0.70 - 0.90):** The action is escalated to the **Orchestrator Dashboard** for asynchronous human approval. The agent can proceed with other tasks while awaiting review.
    *   **Low Confidence (< 0.70):** The action is automatically rejected, and the Planner is signaled to retry the task.
3.  **Sensitive Topic Override:** Any content flagged as a sensitive topic (e.g., politics, finance, health) is **always** escalated for mandatory human review, regardless of its confidence score.

This system ensures that human attention is focused only on the most risky or ambiguous outputs, allowing the swarm to operate with high autonomy for routine tasks.

## 3. Database Strategy

Project Chimera requires a polyglot persistence architecture to handle the diverse types of data within the system.

*   **Semantic Memory (Vector DB - Weaviate):** Agent memories, persona definitions, and world knowledge will be stored in Weaviate. This is essential for the RAG (Retrieval-Augmented Generation) pipeline, enabling agents to have long-term, contextually relevant memory.
*   **Transactional & Relational Data (SQL - PostgreSQL):** Core business data, including user accounts (for multi-tenancy), campaign configurations, agent metadata (not the memories themselves, but the agent's core record), and operational logs will be stored in PostgreSQL. Its transactional integrity is crucial for maintaining a consistent system state.
*   **Episodic Memory & Queues (In-Memory - Redis):** Redis will serve two critical functions: as a high-speed cache for short-term episodic memory (e.g., the last hour of interactions) and as the message broker for the Task and Review queues that coordinate the Planner-Worker-Judge workflow.

### Strategy for High-Velocity Video Metadata

For storing "high-velocity video metadata," a hybrid approach is recommended:

*   **NoSQL (Weaviate) for Search & Discovery:** The primary copy of the video metadata, especially descriptive and semantic information (e.g., topics, objects detected, sentiment, style), should be stored in Weaviate. This allows for powerful semantic search capabilities (e.g., "find all videos with a futuristic, optimistic vibe"). The vector embeddings of the video content itself would be stored here.
*   **SQL (PostgreSQL) for Analytics & Relations:** A structured subset of the metadata (e.g., `video_id`, `agent_id`, `creation_timestamp`, `view_count`, `associated_campaign_id`) should be stored in PostgreSQL. This enables structured queries, aggregations for business intelligence, and enforcing relational integrity between videos, agents, and campaigns.

This dual-storage strategy provides the best of both worlds: the powerful semantic search of a vector database and the robust, structured querying capabilities of a traditional RDBMS.
